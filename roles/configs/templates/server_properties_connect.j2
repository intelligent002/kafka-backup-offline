########################################################################################################################
# CONNECT CONFIG
########################################################################################################################
# A list of host/port pairs to use for establishing the initial connection to the Kafka cluster.
bootstrap.servers={% for host in (groups['combined'] | default([])) + (groups['brokers'] | default([])) %}
{{ hostvars[host]['hostname'] }}:{{ hostvars[host]['port_consumer_mtls_ext'] }}{% if not loop.last %},{% endif %}{% endfor %}

# unique name for the cluster, used in forming the Connect cluster group. Note that this must not conflict with consumer group IDs
group.id=cluster-connect

########################################################################################################################
# Converters / Serders
# this settings are used for connect server itself.
# The converters specify the format of data in Kafka and how to translate it into Connect data.
# Every Connector will need to configure these based on the format they want their data in Kafka
# key.converter=org.apache.kafka.connect.json.JsonConverter
# value.converter=org.apache.kafka.connect.json.JsonConverter

# Converter-specific settings can be passed in by prefixing the Converter's setting with the converter we want to apply it to
key.converter=io.confluent.connect.avro.AvroConverter
key.converter.schemas.enable=true
key.converter.schema.registry.url=https://{{ hostvars['node-00']['hostname'] }}:{{ port_schema_balancer_ext }}
key.converter.schema.registry.ssl.key.password={{ certificate_password }}
key.converter.schema.registry.ssl.keystore.location=/etc/kafka/secrets/admin.jks
key.converter.schema.registry.ssl.keystore.password={{ certificate_password }}
key.converter.schema.registry.ssl.truststore.location=/etc/kafka/secrets/shared.truststore.jks
key.converter.schema.registry.ssl.truststore.password={{ certificate_password }}

value.converter=io.confluent.connect.avro.AvroConverter
value.converter.schemas.enable=true
value.converter.schema.registry.url=https://{{ hostvars['node-00']['hostname'] }}:{{ port_schema_balancer_ext }}
value.converter.schema.registry.ssl.key.password={{ certificate_password }}
value.converter.schema.registry.ssl.keystore.location=/etc/kafka/secrets/admin.jks
value.converter.schema.registry.ssl.keystore.password={{ certificate_password }}
value.converter.schema.registry.ssl.truststore.location=/etc/kafka/secrets/shared.truststore.jks
value.converter.schema.registry.ssl.truststore.password={{ certificate_password }}

########################################################################################################################
# Connect System Topics

# Topic to use for storing offsets. This topic should have many partitions, be replicated and compacted.
offset.storage.cleanup.policy=compact
offset.storage.partitions=50
offset.storage.replication.factor={{ ((groups['brokers'] | default([])) | length) }}
offset.storage.topic=__connect_offset

# Topic to use for storing connector and task configurations; note that this should be a single partition, highly replicated,and compacted topic.
config.storage.cleanup.policy=compact
config.storage.partitions=1
config.storage.replication.factor={{ ((groups['brokers'] | default([])) | length) }}
config.storage.topic=__connect_config

# Topic to use for storing statuses. This topic can have multiple partitions and should be replicated and compacted.
status.storage.cleanup.policy=compact
status.storage.partitions=5
status.storage.replication.factor={{ ((groups['brokers'] | default([])) | length) }}
status.storage.topic=__connect_status

########################################################################################################################
# Flushing
offset.flush.interval.ms=60000

########################################################################################################################
# Transactions
# Whether to enable exactly-once support for source connectors in the cluster by using transactions to write source
# records and their source offsets, and by proactively fencing out old task generations before bringing up new ones.
exactly.once.source.support=ENABLED

########################################################################################################################
# REST API
# List of comma-separated URIs the REST API will listen on. The supported protocols are HTTP and HTTPS.
listeners=https://{{ hostvars[inventory_hostname]['hostname'] }}:{{ hostvars[inventory_hostname]['port_connect_rest_int'] }}

# The Hostname & Port that will be given out to other workers to connect to i.e. URLs that are routable from other servers.
# If not set, the value for "listeners" if used
rest.advertised.host.name={{ hostvars[inventory_hostname]['hostname'] }}
rest.advertised.port={{ hostvars[inventory_hostname]['port_connect_rest_ext'] }}
rest.advertised.listener=HTTPS

########################################################################################################################
# SSL Configuration
security.protocol=SSL
ssl.client.auth=required
ssl.protocol=TLSv1.3
ssl.enabled.protocols=TLSv1.3
ssl.endpoint.identification.algorithm=HTTPS
ssl.key.password={{ certificate_password }}
ssl.keystore.location=/etc/kafka/secrets/{{ hostvars[inventory_hostname]['hostname'] }}.jks
ssl.keystore.password={{ certificate_password }}
ssl.keystore.type=JKS
ssl.truststore.location=/etc/kafka/secrets/shared.truststore.jks
ssl.truststore.password={{ certificate_password }}
ssl.truststore.type=JKS

########################################################################################################################
# SASL Configuration
# uncomment for SASL_SSL , comment for mTLS
# sasl.mechanism=SCRAM-SHA-512
# sasl.jaas.config="org.apache.kafka.common.security.scram.ScramLoginModule required username=\"######\" password=\"#####\";"

########################################################################################################################
# Connectors related
# `All`, meaning connector configurations can override all client properties. The other possible policies in
# the framework include `None` to disallow connectors from overriding client properties, and `Principal` to
# allow connectors to override only client principals.
connector.client.config.override.policy=All

########################################################################################################################
# Set to a list of filesystem paths separated by commas (,) to enable class loading isolation for plugins
# plugin.path=/usr/local/share/java,/usr/local/share/kafka/plugins,/opt/connectors,
plugin.path=/usr/share/java

########################################################################################################################
# SSL Configuration for source connectors:
producer.bootstrap.servers={% for host in (groups['combined'] | default([])) + (groups['brokers'] | default([])) %}
{{ hostvars[host]['hostname'] }}:{{ hostvars[host]['port_consumer_mtls_ext'] }}{% if not loop.last %},{% endif %}{% endfor %}


producer.security.protocol=SSL
producer.ssl.key.password={{ certificate_password }}
producer.ssl.keystore.location=/etc/kafka/secrets/connector.jks
producer.ssl.keystore.password={{ certificate_password }}
producer.ssl.truststore.location=/etc/kafka/secrets/shared.truststore.jks
producer.ssl.truststore.password={{ certificate_password }}

########################################################################################################################
# SSL Configuration for sink connectors:
consumer.bootstrap.servers={% for host in (groups['combined'] | default([])) + (groups['brokers'] | default([])) %}
{{ hostvars[host]['hostname'] }}:{{ hostvars[host]['port_consumer_mtls_ext'] }}{% if not loop.last %},{% endif %}{% endfor %}


consumer.security.protocol=SSL
consumer.ssl.key.password={{ certificate_password }}
consumer.ssl.keystore.location=/etc/kafka/secrets/connector.jks
consumer.ssl.keystore.password={{ certificate_password }}
consumer.ssl.truststore.location=/etc/kafka/secrets/shared.truststore.jks
consumer.ssl.truststore.password={{ certificate_password }}
