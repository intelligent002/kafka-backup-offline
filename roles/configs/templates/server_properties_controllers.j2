# CONTROLLER CONFIG
########################################################################################################################
# Node ID
node.id={{ node_id }}

# Unique cluster ID that must match across all nodes (controller and broker)
cluster.id={{ cluster_id }}

# Define the roles for this node (controller/broker/connect)
process.roles=controller

########################################################################################################################
# Controller KRaft Quorum Configuration

# Specify the name of the listener used for controller communication
controller.listener.names=CONTROLPLANE-{{ hostvars[inventory_hostname]['port_control_plane_int'] }}

# Define the quorum of controllers with their respective node IDs and addresses
controller.quorum.voters={% for host in (groups['combined'] | default([])) + (groups['controllers'] | default([])) %}
{{ hostvars[host]['node_id'] }}@{{ hostvars[host]['hostname'] }}:{{ hostvars[host]['port_control_plane_ext'] }}{% if not loop.last %},{% endif %}{% endfor %}


# Maximum time in milliseconds to wait without being able to fetch from the leader before triggering a new election
controller.quorum.election.timeout.ms=30000

########################################################################################################################
# Control Plane listener

#listener.name.controlplane-{{ hostvars[inventory_hostname]['port_control_plane_int'] }}.sasl.enabled.mechanisms=SCRAM-SHA-512
#listener.name.controlplane-{{ hostvars[inventory_hostname]['port_control_plane_int'] }}.scram-sha-512.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required username="admin" password="{{ credentials | selectattr('username', 'equalto', 'admin') | map(attribute='password') | first }}";
listener.name.controlplane-{{ hostvars[inventory_hostname]['port_control_plane_int'] }}.ssl.keystore.location=/etc/kafka/secrets/{{ hostvars[inventory_hostname]['hostname'] }}.jks
listener.name.controlplane-{{ hostvars[inventory_hostname]['port_control_plane_int'] }}.ssl.keystore.password={{ certificate_password }}
listener.name.controlplane-{{ hostvars[inventory_hostname]['port_control_plane_int'] }}.ssl.keystore.type=JKS
listener.name.controlplane-{{ hostvars[inventory_hostname]['port_control_plane_int'] }}.ssl.truststore.location=/etc/kafka/secrets/shared.truststore.jks
listener.name.controlplane-{{ hostvars[inventory_hostname]['port_control_plane_int'] }}.ssl.truststore.password={{ certificate_password }}
listener.name.controlplane-{{ hostvars[inventory_hostname]['port_control_plane_int'] }}.ssl.truststore.type=JKS
listener.name.controlplane-{{ hostvars[inventory_hostname]['port_control_plane_int'] }}.ssl.client.auth=required

########################################################################################################################
# Common listener configuration

# Map listeners to their respective security protocols
listener.security.protocol.map=CONTROLPLANE-{{ hostvars[inventory_hostname]['port_control_plane_int'] }}:SSL

# Controller listeners
listeners=CONTROLPLANE-{{ hostvars[inventory_hostname]['port_control_plane_int'] }}://:{{ hostvars[inventory_hostname]['port_control_plane_int'] }}

########################################################################################################################
# Authorization

# Hostname verification in SSL certificates (HTTPS - enable, empty - disable)
ssl.endpoint.identification.algorithm=HTTPS

# Defines the authorizer class to enable ACL-based authorization
authorizer.class.name=org.apache.kafka.metadata.authorizer.StandardAuthorizer

# Global fallback per SASL authentication mechanisms (SCRAM-SHA-256/512 for SSL, PLAIN for plaintext, EMPTY to disable globally)
# This is a global fallback setting.
# Listener settings will take precedence.
sasl.enabled.mechanisms=SCRAM-SHA-512

# Specifies superusers that bypass the ACL checks
super.users={% for host in groups['controllers'] | default([]) + groups['brokers'] | default([]) %}
User:CN={{ hostvars[host]['hostname'] }};User:{{ hostvars[host]['hostname'] }}{% if not loop.last %};{% endif %}{% endfor %};User:CN=admin;User:admin;


########################################################################################################################
# Replication

# The replication factor for automatically created topics, and for topics created with -1 as the replication factor
default.replication.factor={{ ((groups['brokers'] | default([])) | length) }}

# When a producer sets acks to "all" (or "-1"), min.insync.replicas specifies the minimum number of replicas
# that must acknowledge a write for the write to be considered successful.
min.insync.replicas={{ ((groups['brokers'] | default([])) | length) }}

# The replication factor for the __consumer_offsets topic (set higher to ensure availability).
# Internal topic creation will fail until the cluster size meets this replication factor requirement.
offsets.topic.replication.factor={{ ((groups['brokers'] | default([])) | length) }}

# The minimum number of replicas that must acknowledge a write to transaction topic in order to be considered successful.
transaction.state.log.min.isr={{ ((groups['brokers'] | default([])) | length) }}

########################################################################################################################
# Transactions

# The replication factor for the __transaction_state topic (set higher to ensure availability).
# Internal topic creation will fail until the cluster size meets this replication factor requirement.
transaction.state.log.replication.factor={{ ((groups['brokers'] | default([])) | length) }}

# Number of partitions for the __transaction_state topic
transaction.state.log.num.partitions=50

# The interval at which to rollback transactions that have timed out
transaction.abort.timed.out.transaction.cleanup.interval.ms=300000

########################################################################################################################
# Performance Settings

# The number of threads that the server uses for receiving requests from the network and sending responses to the network.
# Noted: each listener (except for controller listener) creates its own thread pool.
num.network.threads=6

# The number of threads that the server uses for processing requests, which may include disk I/O
num.io.threads=8

# The number of threads per data directory to be used for log recovery at startup and flushing at shutdown
num.recovery.threads.per.data.dir=2

########################################################################################################################
# Log Flush Policy

# The number of messages accumulated on a log partition before messages are flushed to disk.
log.flush.interval.messages=10000

# The maximum time in ms that a message in any topic is kept in memory before flushed to disk.
# If not set, the value in log.flush.scheduler.interval.ms is used
log.flush.interval.ms=1000

########################################################################################################################
# Security Settings

# Enable/Disable automatic topic creation (recommended to disable for production)
auto.create.topics.enable=true

# Enforce re-authentication every 24 hours
connections.max.reauth.ms=86400000

########################################################################################################################
# Data and Metadata Storage

# Directory where the broker data are stored
log.dirs=/var/lib/kafka/data

# Directory where the broker metadata are stored
metadata.log.dir=/var/lib/kafka/meta

# The frequency in milliseconds that the log cleaner checks whether any log is eligible for deletion
log.retention.check.interval.ms=300000

# The number of hours to keep a log file before deleting it (in hours)
# This is a global fallback setting.
# Topic retention setting will take precedence.
log.retention.hours=168

# Maximum size of a single log segment before it is rolled over (in bytes, 1 GB)
log.segment.bytes=1073741824

# Enable log cleaner for log compaction
log.cleaner.enable=true