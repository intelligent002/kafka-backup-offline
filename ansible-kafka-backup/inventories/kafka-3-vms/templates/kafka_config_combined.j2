# Node ID
node.id={{ node_id }}

# Define the roles for this node (controller and broker)
process.roles=broker,controller

# Unique cluster ID that must match across all nodes (controller and broker)
cluster.id={{ cluster_id }}

#############################################################################################
# Controller Quorum Configuration

# Define the quorum of controllers with their respective node IDs and addresses
controller.quorum.voters={% for host in groups['combined'] + groups['controllers'] if 'port_controller_ext' in hostvars[host] %}
{{ hostvars[host]['node_id'] }}@{{ hostvars[host]['hostname'] }}:{{ hostvars[host].port_controller_ext }}{% if not loop.last %},{% endif %}{% endfor %}

# Timeout for controller quorum elections (in milliseconds)
controller.quorum.election.timeout.ms=10000

#############################################################################################
# Listeners and Communication

# Define the listener for controller-to-controller communication
listeners=CONTROLLER://0.0.0.0:{{ port_controller_ext }},PLAINTEXT://0.0.0.0:{{ port_broker_ext | default(9092) }}

# Advertise the broker listener for clients to connect
advertised.listeners=PLAINTEXT://{{ hostname }}:{{ port_broker_ext | default(9092) }}

# Specify the name of the listener used for controller communication
controller.listener.names=CONTROLLER

# Specifies the listener name used for communication between brokers
inter.broker.listener.name=PLAINTEXT

#############################################################################################
# Data and Metadata Storage

# Directory where the controller's metadata logs and broker data are stored
log.dirs=/var/lib/kafka/data

#############################################################################################
# Internal Topics Configuration

# Replication factor for the __consumer_offsets topic
offsets.topic.replication.factor=3

# Replication factor for the __transaction_state topic
transaction.state.log.replication.factor=3

# Minimum number of in-sync replicas required for transactional writes
transaction.state.log.min.isr=2

# Number of partitions for the __transaction_state topic
transaction.state.log.num.partitions=10

#############################################################################################
# Transactions

# Defines how often the broker will clean up expired or timed-out transactions
transaction.abort.timed.out.transaction.cleanup.interval.ms=300000

#############################################################################################
# Log Retention Policies

# Retention period for logs before they are eligible for deletion (in hours)
log.retention.hours=168

# Maximum size of a single log segment before it is rolled over (in bytes, 1 GB)
log.segment.bytes=1073741824

# Interval for checking and applying log retention policies (in ms)
log.retention.check.interval.ms=300000

# Enable log cleaner for log compaction
log.cleaner.enable=true

#############################################################################################
# Performance Settings

# Number of threads for handling network requests
num.network.threads=6

# Number of threads for handling I/O operations
num.io.threads=8

# Number of threads for log recovery during broker startup or failure recovery
num.recovery.threads.per.data.dir=2

#############################################################################################
# Log Flush Policy

# Messages are immediately written to the filesystem but by default we only fsync() to sync
# the OS cache lazily. The following configurations control the flush of data to disk.
# There are a few important trade-offs here:
#    1. Durability: Unflushed data may be lost if you are not using replication.
#    2. Latency: Very large flush intervals may lead to latency spikes when the flush does occur as there will be a lot of data to flush.
#    3. Throughput: The flush is generally the most expensive operation, and a small flush interval may lead to excessive seeks.
# The settings below allow one to configure the flush policy to flush data after a period of time or
# every N messages (or both). This can be done globally and overridden on a per-topic basis.

# The number of messages to accept before forcing a flush of data to disk
log.flush.interval.messages=10000

# The maximum amount of time a message can sit in a log before we force a flush
log.flush.interval.ms=1000

#############################################################################################
# Security Settings (Optional for Production)

# Enable/Disable automatic topic creation (recommended to disable for production)
auto.create.topics.enable=true
